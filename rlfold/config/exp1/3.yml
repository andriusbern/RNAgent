main:
    model: PPO2
    policy: CustomCnnPolicy
    n_workers: 2
    n_steps: 2000000
    multi_discrete: false
    frame_stack: 0
    seed: 1
models:
    PPO2:
        gamma: 1
        n_steps: 256
        ent_coef: 0.01
        learning_rate: 0.9e-04
        vf_coef: 0.5
        max_grad_norm: 0.5
        lam: 0.95
        nminibatches: 4
        noptepochs: 3
        cliprange: 0.1
        full_tensorboard_log: false
        verbose: 0
policies:
    CnnPolicy: {}
    CustomCnnPolicy: 
        filters:
        - 8
        - 128
        - 8
        kernel_size:
        -   - 6
            - 1
        -   - 1
            - 25
        -   - 1
            - 15
        stride:
        - 1
        - 1
        - 1
        lstm: []
        shared:
        - 128
        h_actor:
        - 32
        h_critic:
        - 16
        activ: relu
        pd_init_scale: 0.05
        conv_init_scale: 1.4
        kernel_initializer: glorot_normal_initializer
        init_bias: 0.5
    CustomCnnLstmPolicy: {}
    MlpPolicy: {}
environment:
    kernel_size: 36
    reward_exp: 9
    full_state: true
    write_threshold: 0
    meta_learning: true
    seq_len:
        - 80
        - 81
        - 82
        - 83
        - 84
    seq_count: 200
    seq_nr: 0
    randomize: true

