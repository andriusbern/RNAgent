main:
    model: PPO2
    policy: CustomCnnPolicy
    n_workers: 12
    n_steps: 2500000
    multi_discrete: false
    frame_stack: 0
    seed: 1
models:
    PPO2:
        gamma: 1
        n_steps: 256
        ent_coef: 0.01
        n_steps: 64
        ent_coef: 0.002
        learning_rate: 0.9e-04
        vf_coef: 0.5
        max_grad_norm: 0.5
        lam: 0.95
        nminibatches: 4
        noptepochs: 3
        cliprange: 0.1
        full_tensorboard_log: false
        verbose: 0
policies:
    CnnPolicy: {}
    CustomCnnPolicy: 
        filters:
        - 12
        - 256
        - 128
        - 8
        kernel_size:
        # - - 6
        - - 6
          - 1
        - - 1
          - 25
        - - 1
          - 10
        - - 1
          - 5
        # - - 1
        #   - 5
        stride:
        - 1
        - 1
        - 1
        - 1
        lstm: []
        shared:
        - 128
        h_actor:
        - 32
        h_critic:
        - 16
        activ: relu
        pd_init_scale: 0.05
        conv_init_scale: 1.4
        kernel_initializer: glorot_normal_initializer
        init_bias: 0.5
    CustomCnnLstmPolicy: {}
    MlpPolicy: {}
environment:
    kernel_size: 32
    reward_exp: 9
    full_state: true
    write_threshold: 0
    meta_learning: true
    seq_len:
        - 82
        - 83
        - 84
        - 85
        - 86
        - 87
        - 88
        - 89
        - 90
    seq_count: 200
    seq_nr: 0
    randomize: true

