main:
    model: PPO2
    policy: CustomCnnPolicy
    n_workers: 2
    n_steps: 2000000
    multi_discrete: false
    frame_stack: 0
    seed: 1
models:
    PPO2:
        gamma: 1
        n_steps: 256
        ent_coef: 0.0001
        learning_rate: 1.0e-05
        vf_coef: 0.4
        max_grad_norm: 0.5
        lam: 0.95
        nminibatches: 8
        noptepochs: 3
        cliprange: 0.1
        full_tensorboard_log: false
        verbose: 0
policies:
    CnnPolicy: {}
    CustomCnnPolicy: 
        filters:
        - 64
        - 32
        kernel_size:
        -   - 3
            - 17
        -   - 3
            - 7
        stride:
        - 1
        - 1
        lstm: []
        shared:
        - 512
        - 256
        h_actor:
        - 64
        - 16
        h_critic:
        - 16
        activ: relu
        pd_init_scale: 0.05
        conv_init_scale: 1.4
        kernel_initializer: glorot_normal_initializer
        init_bias: 0.5
    CustomCnnLstmPolicy: {}
    MlpPolicy: {}
environment:
    kernel_size: 32
    reward_exp: 9
    full_state: true
    write_threshold: 0
    meta_learning: true
    seq_len:
        - 100
        - 200
        - 300
    seq_count: 120
    seq_nr: 0
    randomize: true

